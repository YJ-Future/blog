# mysql实战45讲
## 01基础架构：一条查询语句是如何执行的
- MySQL分为两部分：  
  - Server层  
    提供了MySQL大多数核心服务功能，以及所有的内置函数（比如：日期、时间、数学、加密函数）  
    所有跨存储引擎的功能都在这一层实现（比如：视图、触发器、存储过程）  
    大概包括：连接器、查询缓存、分析器、优化器、执行器等
    - 连接器  
      负责跟客户端建立连接、获取权限、维持和管理连接。  
      1. 首先客户端发起到服务端的连接，经过了TCP握手。
      2. 连接器进行身份校验，获取连接时指定的用户名和密码
      3. 根据连接指定的用户名读取该用户拥有的权限（如果在此之后修改了该用户权限，则对此连接不可见）  
      通过命令show processlist可以查看当前连接数据库的连接信息。如果连接空闲，则Command列对应值为Sleep。连接尝试没有请求，则连接器会断开  
      该连接，控制参数为wait_timeout，默认8小时，可通过 show global variables like 'wait_timeout' 命令查看。  
      MySQL在执行过程中临时使用的内存保存在连接对象中，这些内存在连接断开时才会释放（5.7及以后版本可以通过执行 mysql_reset_connection  
      方法重新初始化连接资源，不需要重新连接和重新权限校验的过程）  
    - 查询缓存  
      在连接建立完成之后，就可以通过查询语句先从查询缓存中获取缓存结果，如果能获取到则直接返回；否则继续后续的查询流程，查询出结果之后再放到查询  
      缓存内存中，然后返回查询结果。查询缓存类似key-value键值对，key为查询语句，value为对应的缓存结果。   
      查询缓存在对应表上有更新之后，会失效，从查询缓存中清除。那么一个更新比较频繁的表，就不适合使用查询缓存，命中率较低。  
      MySQL查询是否开启了查询缓存命令为： show variables 'query_cache_type' . 0为禁用，1为开启，2为DEMAND。DEMAND是按需使用的意思，  
      可以在SQL中增加SQL_CACHE使用，比如 ```select SQL_CACHE * from T where id = 1;```。 从MySQL8.0版本开始就没有查询缓存的功能了。  
    - 分析器  
      分析器负责弄清楚SQL语句要干什么，对SQL语句进行词法分析和语法分析。分析器会校验SQL语法，不符合的会提示错误。同时也会校验查询的字段是否在表中存在。  
    - 优化器  
      优化器负责语句确定最优的执行方案。比如：  
      1. 当查询语句中可以选择多个索引执行，优化器则负责决定使用哪个索引进行查询。 
      2. 一个多表关联查询语句，需要确定最优的查询表的顺序。  
      优化器阶段完成之后，已经确定了语句的执行方案。  
    - 执行器
      执行器负责执行语句。执行开始，先判断当前用户对要操作的表有没有查询权限，如果没有，则返回无权限的错误提示；有则继续后续执行：打开表，根据表   
      的引擎的定义，去选择相应引擎的接口进行数据查询。  
      具体调用引擎接口查询步骤大概如下：  
      1. 调用获取满足条件的第一行数据的接口（比如查询条件没有可走索引的列，则获取表的第一行数据）
      2. 循环调用获取满足条件下一行数据的接口  
      在慢sql日志文件中 Rows examine 代表：查询执行过程中，调用了引擎接口获取数据的次数和统计。一次引擎接口调用可能不止扫描一行数据，所以真正的  
      引擎扫描行数跟Rows examine并不完全相同。  
  - 存储引擎层    
    负责数据存储和获取。采用插件式架构模式，支持Innodb、MyISAM、Memory等多个存储引擎。最常用的存储引擎是Innodb，从MySQL5.5.5开始   作为默认存储引擎。   
## 02日志系统：一条更新语句是如何执行的  
更新语句的具体例子  
- 表T，字段：id long 索引，age int
- 更新语句：```update T set age = age + 1 where id = 1;```   
更新语句执行大致流程：
1. 连接到数据库，经过连接器的处理。
2. 分析器进行词法和语法分析，判断出来为更新语句。
3. 优化器选择走索引id，然后找到对应行，进行更新。
更新语句对比查询语句执行流程，还需要涉及两个重要的日志模块：重做日志 redo log 和 归档日志 binlog  
- redo log
InnoDB存储引擎特有的日志文件。采用的WAL技术，即Write Ahead Logging，先写日志，再写磁盘。  
1. 需要更新一条记录时，InnoDB存储引擎先将记录写到redo log中，并更新内存。  
2. InnoDB会在适合的时间，将操作记录更新到磁盘中。  
InnoDB的redo log的大小是固定的，比如配置一组日志包括4个文件，每个文件大小1G。写入为循环写入。  
包括两个重要的位置：  
    - 日志写入位置 write position，重做日志要写入的位置。  
    - 检查点位置 checkpoint，当前已经把当前位置之前的更新记录更新到磁盘数据文件中，当前位置之前一直到日志写入位置的日志文件已经可重用了。
redo log的作用：保证数据库crash了，也能保证数据完整安全，即crash-safe。加入数据库因为异常宕机，这段时间还没有刷新回磁盘的更新数据会丢失，但是  
通过重启数据库，数据库可以通过redo log恢复丢失的数据更新。
为什么不能不使用重做日志，直接把要更新的数据都刷新到磁盘文件？【自己的一点观点，后续应该会再更新】  
1. 更新的数据往往都是磁盘随机的、不连续，如果每一次更新操作都需要写入磁盘一次，随机IO很频繁，写入磁盘性能差。
2. 重做日志则是顺序记录，写入文件是连续的，写入性能高，之后再相对较慢的更新数据磁盘文件。
- binlog
Server层的二进制日志文件，也称为归档日志。最初MySQL中不存在InnoDB引擎，自带的引擎是MyISAM，MyISAM不能保证crash-safe，Server层已经有binlog  
日志，用于归档。之后InnoDB引擎，为了实现crash-safe则引入了redo log。  

- redo log和binlog区别  
1. binlog是所有存储引擎都有的，redo log则是InnoDB引擎特有的。
2. binlog记录的是逻辑日志，记录了记录是如何变更的，具体记录格式又可分为三种：statement（记录执行的sql语句）、row（记录变更前数据信息，以及记录变更后的数据信息）  、 
  mixed（涉及到一些随机函、当前时间等不确定性的函数使用row格式的，其他的都使用statement格式）。 redo log是物理日志，记录的是行所在数据页发生的变更后信息。  
3. binlog是追加写，写完一个binlog日志文件之后，可以新创建一个文件继续写。redo log是循环写入，会存在覆盖写的情况。  
4. 写入时间不同。redo log写入是在每次更新数据时将日志写入到重做日志缓冲中，然后按照一定条件顺序写入到磁盘中的重做日志文件中（比如主线程每秒从缓冲中刷新回磁盘，    
  设置innodb_flush_log_at_trx_commit，0：事务提交时，不会刷新日志缓冲到磁盘；1：事务提交时，刷新缓冲到磁盘，并且是同步写磁盘 fsysnc；2：事务提交时，刷新    
  缓冲到磁盘，缓冲写磁盘，不是同步写入）。    
  binlog是在更新数据时，先把数据写入到缓存中，等到事务提交时，将缓冲二进制文件内容刷新到磁盘的二进制文件中（这里的写入也是缓冲写，如果要保证每次事务提交之前，保证  
  缓冲同步写入磁盘，则设置参数sync_binlog=1）。  
- 更新语句在执行器中具体的执行过程
  1. 执行器根据索引id，通过树直接找到id=1的数据行，然后判断该数据行所在的数据页是不是在内存中，如果在了，则直接返回内存中的数据给执行器；否则从磁盘读取数据页到内存  
    中，然后返回给执行器。
  2. 执行器获取到存储引擎返回的数据，然后进行更新：age+1，然后调用存储引擎写入接口，把更新后的数据写入。
  3. 存储引擎写入接口中会把需要更新的数据更新到内存中，同时会记录该更新操作到redo log中，此时redo log为prepare准备状态。然后通知执行器执行完成，可以随时提交事务。
  4. 执行器会生成更新操作的binlog，并把binlog内容写入到磁盘binlog文件中。
  5. 执行器调用存储引擎的提交事务接口，引擎会把刚刚写入的redo log状态改成commit已提交状态，则到此更新完成。
- 数据恢复过程
  1. 找到最近一份数据库的全量备份。
  2. 从该备份的时间点开始，将从该点开始一直到现在的时间段中生成的binlog文件获取到并进行重放。
- 两阶段提交
  redo log和binlog采用两阶段提交方式，保证两者的逻辑一致。  
  1. redo log写入文件之后，状态为prepare。
  2. 然后写入binlog成功。
  3. 事务提交，redo log状态改为commit。 
  如果在3 事务提交之前，数据库发生宕机，则数据库重启时，会检测到redo log是prepare的，binlog数据也完整，则会自动再进行提交，完成事务。
  
## 03事务隔离：为什么你改了我还看不见
事务要保证一组数据库操作全部成功或全部失败。MySQL事务支持是在存储引擎中实现的，比如InnoDB支持事务，但是MyISAM则不支持事务。  
事务的特性：A（原子性）、C（一致性）、I（隔离性）、D（持久性）  
在数据库上同时有多个事务在执行时，会出现常见的几个问题：脏读、不可重复读、幻读。不同的隔离级别相应解决这几个问题。  
隔离界别种类：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）、串行化（serializable）。隔离级别和效率是负相关的，隔离级别越高，相应效率越低。  
隔离级别：  
- 读未提交：一个事务可以看到到其他未提交事务对数据的变更。会存在脏读的问题。  
- 读提交：一个事务只能看到其他已提交事务对数据的变更。会存在不可重复读的问题。
- 可重复读：一个事务执行过程中看到的数据，在整个事务过程中都保持和该事务开始看到的数据一致。一个事务看不到其他未提交或者已提交的事务对该事务看到数据的变更（该事务的更新语句则可以获取到当前最新的数据，其他已提交事务的变更，比如update T set a = a + 1 where id = 1,，则a获取到的值是当前最新的值）。存在幻读的问题。  
- 串行化：对同一行记录，读取加读锁、写加写锁，当出现读、写锁冲突时，必须等当前事务执行完成之后，后访问的事务才能继续执行。

|  | 读锁 | 写锁 |
| :---:|:---:|:---:|
| 读锁 | √ | × |
| 写锁 | × | × |

读锁和写锁会互斥，需要串行化，避免幻读问题。对比可重复读隔离级别，假如存在读锁概念：

|  | 读锁 | 写锁 |
| :---:|:---:|:---:|
| 读锁 | √ | √ |
| 写锁 | √ | × |

事务隔离级别配置参数：transaction-isolation

#### 隔离实现：  
数据库存储引擎会创建一个视图（read view），查询数据时会以该视图的结果为准。   
- 读提交：每条查询语句开始执行时创建一个视图。每条语句查询直接返回记录的最新值。
- 可重复读：事务启动时创建一个视图，这个事务从开始直到结束都使用同一个视图。    
- 串行化：通过加锁，避免并行访问。
  
具体以可重复读为例介绍隔离具体实现：  
- 在MySQL中每条记录可以存在多个版本，每条记录在更新的时候，都会同时记录一条回滚（undo）操作，这样当前最新的值通过回滚操作可以得到上一个版本的值。  
- undo日志会在不再被使用到的时候删除，即所有的read-view视图对应的版本都已经在这个版本之后了，比如最早的read-view对应的记录版本为B，同时 A-》B，A早于B版本，则B到A版本的回滚日志可以删除了。（当系统里没有比这个回滚日志更早的read-view的时候）  

为什么建议尽量不使用长事务？
- 造成undo回滚日志文件会占用很大空间，且undo操作记录被删除也不会缩小文件占用的空间。从事务开启到结束，这个期间的数据库数据更新对应的undo操作记录会一直保留，因为
在事务执行期间，肯能会访问数据库的任意数据记录，为了保证一致性读，则需要保留undo日志。（在MySQL5.5及以前版本，回滚日志、数据字典都存放在系统表空间ibdata文件中。）
- 锁持有时间太长，会造成竞争同一个锁的其他事务被阻塞，数据库性能变差，甚至拖垮整个库。

事务启动方式：
- 显示启动事务，使用语句begin/start transaction启动事务，提交事务使用语句commit，回滚事务语句为rollback。  
- 通过set autocommit = 0命令关闭这个线程事务自动提交。当你执行一个select查询时，事务启动了，且不会自动提交，只有你主动执行commit或者rollback
命令，或者断开连接。一些客户端连接框架（比如一些数据库连接池）默认建立数据库连接成功之后，会先执行set autocommit=0命令。如果是长连接，一直没有提交或回滚，会导致意外的长事务。  
dbcp连接池默认autocommit为1，会自动提交事务。  





  




  



  
  


 


